{
  "version": "1.0",
  "extracted_at_utc": "2026-01-20T03:11:23+00:00",
  "input_url": "https://www.reddit.com/r/automation/comments/1q9xvhw/how_are_you_automating_1000_product_showcase/",
  "canonical_post_url": "https://www.reddit.com/r/automation/comments/1q9xvhw/",
  "json_url": "https://www.reddit.com/r/automation/comments/1q9xvhw.json?raw_json=1&sort=top&limit=300&depth=10",
  "extraction_method": "json+morechildren-session-cookie",
  "post": {
    "id": "1q9xvhw",
    "fullname": "t3_1q9xvhw",
    "subreddit": "automation",
    "title": "How are you automating 1,000+ product showcase videos from photos?",
    "selftext": "How would you automate generating 1,000+ product showcase videos from images (mostly 1 main shot + a few close-ups, all shot in-room)?\n\nCurrent Workflow: Kling / Higgsfield -> Img2Video with camera move prompts -> Stitch clips -> add text (optional).",
    "author": "Admirable_Suspect444",
    "created_utc": 1768133572.0,
    "permalink": "/r/automation/comments/1q9xvhw/how_are_you_automating_1000_product_showcase/",
    "url": "https://www.reddit.com/r/automation/comments/1q9xvhw/how_are_you_automating_1000_product_showcase/",
    "num_comments": 9,
    "score": 4,
    "upvote_ratio": 0.83,
    "is_self": true,
    "locked": false,
    "over_18": false
  },
  "comments": [
    {
      "id": "nyykokp",
      "fullname": "t1_nyykokp",
      "parent_fullname": "t3_1q9xvhw",
      "link_fullname": "t3_1q9xvhw",
      "author": "AutoModerator",
      "body": "Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/about/rules/)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Fautomation) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*",
      "score": 1,
      "created_utc": 1768133572.0,
      "permalink": "/r/automation/comments/1q9xvhw/how_are_you_automating_1000_product_showcase/nyykokp/",
      "depth": 0,
      "is_submitter": false,
      "distinguished": "moderator",
      "stickied": false
    },
    {
      "id": "nyymfqy",
      "fullname": "t1_nyymfqy",
      "parent_fullname": "t3_1q9xvhw",
      "link_fullname": "t3_1q9xvhw",
      "author": "stacktrace_wanderer",
      "body": "We looked at something similar when marketing wanted volume without turning it into a manual edit factory. What helped was getting ruthless about templates and constraints, same camera moves, same clip order, same text rules, then letting automation fill the slots. The moment we allowed per product creativity, it broke down fast and needed human cleanup. In our case, batching and deterministic inputs mattered more than squeezing quality out of each clip. It did not look cinematic, but it was predictable and scaled without constant babysitting. I would focus less on the video model and more on locking the workflow so it cannot drift.",
      "score": 1,
      "created_utc": 1768134424.0,
      "permalink": "/r/automation/comments/1q9xvhw/how_are_you_automating_1000_product_showcase/nyymfqy/",
      "depth": 0,
      "is_submitter": false,
      "distinguished": null,
      "stickied": false
    },
    {
      "id": "nyynmcq",
      "fullname": "t1_nyynmcq",
      "parent_fullname": "t1_nyymfqy",
      "link_fullname": "t3_1q9xvhw",
      "author": "Admirable_Suspect444",
      "body": "What tech stack did you end up using? Thinking about Kling API + local Python.",
      "score": 1,
      "created_utc": 1768134981.0,
      "permalink": "/r/automation/comments/1q9xvhw/how_are_you_automating_1000_product_showcase/nyynmcq/",
      "depth": 1,
      "is_submitter": true,
      "distinguished": null,
      "stickied": false
    },
    {
      "id": "nz2drta",
      "fullname": "t1_nz2drta",
      "parent_fullname": "t3_1q9xvhw",
      "link_fullname": "t3_1q9xvhw",
      "author": "Electrical_Heart_673",
      "body": "are you running the img2video stuff locally or through apis? i've been looking at doing something similar but the cost/time tradeoff of batch processing through kling/higgsfield apis seems brutal at that scale. how long is your whole pipeline taking per product?",
      "score": 1,
      "created_utc": 1768174917.0,
      "permalink": "/r/automation/comments/1q9xvhw/how_are_you_automating_1000_product_showcase/nz2drta/",
      "depth": 0,
      "is_submitter": false,
      "distinguished": null,
      "stickied": false
    },
    {
      "id": "nz2ub7t",
      "fullname": "t1_nz2ub7t",
      "parent_fullname": "t3_1q9xvhw",
      "link_fullname": "t3_1q9xvhw",
      "author": "RobbyInEver",
      "body": "Task scheduler running API's to various video generators that have API's (eg. Runway) then stitch sound, text and voice using ffmpeg based automators and finally using another api to upscale to 2k and 4k.\n\nTitles are created from script using imagickmagick and PHP. Music is AI generated to match either length or mood (if mood then it's just a repeating loop).\n\nSource videos are cropped or canvas expanded if necessary to fit on portrait (eg. TikTok), square (Instagram) and horizontal (YouTube) formats.\n\nFfmpeg also used to modify sounds levels at each point in time (eg. By 30%) whenever the AI voiceover speaks.\n\nAt the end ffmpeg also used to insert both metadata and thumbnails into each video, and at all stages write the status to an online myqsl DB, so that errors and flags can be sent via email if anything jams (mostly due to all backup gen platforms not working when one goes down).\n\nFor more complicated videos, pipeline is paused while an automated prompt (usually email) is sent with link to approve or reject (eg. Video generated before music, titling and voiceover insertion). If rejected the process for that stage is simply repeated.\n\nEach video we produce in this pipeline takes anywhere from 2 to 6 hours to render (shorter if there's little movement or no need to upscale beyond 2k).",
      "score": 1,
      "created_utc": 1768179903.0,
      "permalink": "/r/automation/comments/1q9xvhw/how_are_you_automating_1000_product_showcase/nz2ub7t/",
      "depth": 0,
      "is_submitter": false,
      "distinguished": null,
      "stickied": false
    },
    {
      "id": "nz4me4y",
      "fullname": "t1_nz4me4y",
      "parent_fullname": "t1_nyynmcq",
      "link_fullname": "t3_1q9xvhw",
      "author": "stacktrace_wanderer",
      "body": "We kept it pretty boring on purpose. Local Python to orchestrate, a job queue to batch runs, and a simple config file per product that only allowed a few parameters like image order and text. Video generation was treated as a black box, then stitched with a CLI video tool and overlaid text from templates. The big win was making everything deterministic so reruns gave the same output every time. Once that was locked, scaling was just more compute and better batching.",
      "score": 1,
      "created_utc": 1768204947.0,
      "permalink": "/r/automation/comments/1q9xvhw/how_are_you_automating_1000_product_showcase/nz4me4y/",
      "depth": 2,
      "is_submitter": false,
      "distinguished": null,
      "stickied": false
    },
    {
      "id": "nz5j5u4",
      "fullname": "t1_nz5j5u4",
      "parent_fullname": "t1_nz4me4y",
      "link_fullname": "t3_1q9xvhw",
      "author": "Admirable_Suspect444",
      "body": "Thanks a lot. Appreciate that. And after spending the last couple of hours experimenting with Kling 2.6 i totally agree. You can get absolutely fantastic results, but then every word of the prompt must be spot on and this takes many runs. So yes, goal must be to keep it boring and simple.",
      "score": 2,
      "created_utc": 1768222098.0,
      "permalink": "/r/automation/comments/1q9xvhw/how_are_you_automating_1000_product_showcase/nz5j5u4/",
      "depth": 3,
      "is_submitter": true,
      "distinguished": null,
      "stickied": false
    },
    {
      "id": "nz5s1op",
      "fullname": "t1_nz5s1op",
      "parent_fullname": "t3_1q9xvhw",
      "link_fullname": "t3_1q9xvhw",
      "author": "GetNachoNacho",
      "body": "At that scale, the key is removing decisions. Standardized camera moves, text templates, and naming conventions matter more than the model itself. Consistency beats creativity for 1,000+ outputs.",
      "score": 1,
      "created_utc": 1768225355.0,
      "permalink": "/r/automation/comments/1q9xvhw/how_are_you_automating_1000_product_showcase/nz5s1op/",
      "depth": 0,
      "is_submitter": false,
      "distinguished": null,
      "stickied": false
    },
    {
      "id": "nzd6prg",
      "fullname": "t1_nzd6prg",
      "parent_fullname": "t3_1q9xvhw",
      "link_fullname": "t3_1q9xvhw",
      "author": "sharakorr",
      "body": "Seedance is way more reliable than kling for realism. Higgsfield isn't needed to get camera movement, just prompt it in and seed. Use ffmpeg or creatomate for compilation. Generate images before making them videos. If you want variations, use a creative director agent/llm node then split it up into standard videography roles and use  jobs - script, sound, shots, effects that provide input to each shot before it goes to image generation and video generation. My stack is airtable n8n eleven labs wavespeed/kie ffmpeg/creatomate.",
      "score": 1,
      "created_utc": 1768317949.0,
      "permalink": "/r/automation/comments/1q9xvhw/how_are_you_automating_1000_product_showcase/nzd6prg/",
      "depth": 0,
      "is_submitter": false,
      "distinguished": null,
      "stickied": false
    }
  ],
  "metrics": {
    "expected_num_comments": 9,
    "extracted_unique_comments": 9,
    "remaining_pending_child_ids": 0,
    "missing_children_ids": 0,
    "coverage_estimate": 1.0,
    "stop_reason": "completed",
    "auth_mode": "cookie",
    "requests_total": 1,
    "requests_morechildren": 0,
    "seen_more_nodes_total": 0,
    "pending_child_ids_sample": [],
    "missing_child_ids_sample": [],
    "warnings": [],
    "errors": []
  }
}